## 1 爬虫的基础知识

### 1.1 定义使用场景

##### 1 为什么学习爬虫

**1 数据的来源**

- 企业产生数据（大型企业）
- 数据平台购买数据
- 政府/机构公开的数据
- 数据管理公司提供的数据
- 网络爬取数据

**2**  **用途**

- 进行在网页或者是app上进行展示：  今日头条， 百度新闻，网易云音乐
- 进行数据分析或者是机器学习相关的项目

##### 2 什么是爬虫

网络爬虫就是**模拟浏览器发送网络请求， 接收响应**， 一种按照一定规则， 自动地抓取互联网信息的程序。

**本质：模拟浏览器取获取、处理、保存数据**

##### 3 爬虫的更多用途

- 12306抢票
- 投票
- 短信轰炸
- 制作内容（自己的ideas）

### 1.2 分类和流程

##### 1 分类

- 通用爬虫：所搜引擎的爬虫
- 聚焦爬虫：针对特定网站的爬虫

##### 2 流程（聚焦）

- 向起始url**发送请求**，并**获取响应**
- 对响应进行**提取**   （判断是否是需要自己想要的数据，来决定是否需要再发起url请求）
- 如果提取url，则继续发送请求获取响应
- 如果提取数据，则将数据进行**保存**

百度爬取数据的方式

- 1 提取所有超链接 -- 进入超链接 -- 提取超链接   一直循环提取下去  直到终点
- 2 将得到的网页库放入数据库
- 3  **索引模块** 对于网站中的字符串和对应的超链接， 将字符串切片出来做关键字，建立字符串和对应连接之间的关系 ， 字符串作为key， url作为值
- 4 索引库
- 5 用户查询模块
- 6 最终用户

##### 3 robots协议(君子协议)

上一家公司70%的流量来自搜索引擎

查看robots  https://www.baidu.com/robots

百度黑马 -- 点进去第一个是千峰 -- 交钱多的会排在前面 -- 竞价排名

谷歌 -- 按照点击量排名 -- 广告在右侧的 



```
在百度搜索中，不能搜索到淘宝网中某一个具体的商品的详情页面，这就是robots协议在起作用
```

robots协议：网站通过Robots协议告诉搜索引擎哪些页面可以抓取，哪些页面不能抓取，但它仅仅是互联网中的一般约定  

- 无需遵守该协议 



### 1.3 HTTP 和 HTTPs的复习

**1 记忆 http、https的概念和区别：** 

- http: **超本文传输协议**  80
- https: HTTP + SSL，即带有安全套接字层的超本文传输协议

​         超文本传输协议HTTP协议被用于在Web浏览器和网站服务器之间传递信息，**HTTP协议以明文方式发送内容，不提供任何方式的数据加密，**如果攻击者截取了Web浏览器和网站服务器之间的传输报文，就可以直接读懂其中的信息，因此，HTTP协议不适合传输一些敏感信息，比如：信用卡号、密码等支付信息。

　　为了解决HTTP协议的这一缺陷，需要使用另一种协议：安全套接字层超文本传输协议HTTPS，为了数据传输的安全，HTTPS在HTTP的基础上加入了SSL（Secure Sockets Layer） 协议，SSL依靠**证书来验证服务器的身份**，并为**浏览器和服务器之间的通信加密**。

HTTPS和HTTP的区别主要如下：

　　1、https协议需要到ca申请证书，一般免费证书较少，因而需要一定**费用**。

　　2、http是超文本传输协议，信息是**明文**传输，https则是具有安全性的ssl**加密**传输协议。

　　3、http和https使用的是完全不同的连接方式，用的端口也不一样，前者是80，后者是443。

　　4、http的连接很简单，是**无状态**的；HTTPS协议是由SSL+HTTP协议构建的可进行**加密传输、身份认证**的网络协议，比http协议安全。

HTTPS更安全， 但性能更低。

复习：网络传输-TCP/IP四层模型

- 应用层  HTTP FTP 
- 传输层 TCP   UDP  
- 网络层  IP  
- 网络接口层  

HTTP协议是基于TCP协议的，发送数据之前需要建立好连接 

**2 记忆浏览器发送请求HTTP请求的过程**

1. 浏览器先向地址栏中的url发起**请求**，并获取响应(html)
2. 在返回的响应内容（html）中，会带有css、js、图片等**url地址**，以及**ajax代码**，浏览器**按照响应内容中的顺序**依次发送其他的**请求**，并获取相应的响应
3. 浏览器每获取一个响应就对展示出的结果进行添加（加载），<u>js，css等内容会修改页面的内容，js也可以重新发送请求，获取响应</u>
4. 从获取第一个响应并在浏览器中展示，直到最终获取全部响应，并在展示的结果中添加内容或修改————这个过程叫做浏览器的**渲染**

注意：**在爬虫中，需要以url地址对应的响应为准来进行数据的提取** 

**3 记忆HTTP请求头的形式**

```
GET /item/503/1227315?fr=aladdin HTTP/1.1
请求方法   资源路径        协议 \r\n
Host: www.baidu.com  \r\n
......
```

**请求方法  get     post**

1 参数位置  

- get 参数再请求头中
- post 请求体

2 用途

- get请求数据
- post 提交数据

**请求方式**

根据HTTP标准，HTTP请求可以使用多种请求方法。

HTTP1.0定义了三种请求方法： GET, POST 和 HEAD方法。

HTTP1.1新增了五种请求方法：OPTIONS, PUT, DELETE, TRACE 和 CONNECT 方法。

| 请求方式 | 描述                                                         |
| -------- | ------------------------------------------------------------ |
| GET      | 请求指定的页面信息，并返回实体主体。                         |
| HEAD     | 类似于get请求，只不过返回的响应中没有具体的内容，用于获取报头 |
| POST     | 向指定资源提交数据进行处理请求（例如提交表单或者上传文件）。数据被包含在请求体中。POST请求可能会导致新的资源的建立和/或已有资源的修改。 |
| PUT      | 从客户端向服务器传送的数据取代指定的文档的内容。             |
| DELETE   | 请求服务器删除指定的页面。                                   |
| CONNECT  | <u>HTTP/1.1协议中预留给能够将连接改为管道方式的代理服务器</u>。 |
| OPTIONS  | 允许客户端查看服务器的性能。                                 |
| TRACE    | 回显服务器收到的请求，主要用于测试或诊断。                   |

**请求头**

Host：主机和端口

accept: 浏览器告诉服务器, 自己能够**接收并识别**的文件类型 

accept-Ecoding：浏览器支持的**压缩格式**（减小传输数据量， 传输数据快， 但是一边要压缩， 另一边要解压， 会多占用一些服务器资源）

accept - language：浏览器可以接收的文本语言 

cache - control：缓存机制

connection：浏览器和服务器之间的连接方式    长链接还是短连接

**cookie**： Cookie 

upgrade-insecure-resquest   :  http 升级为 `HTTPS` 请求 

**referer**:从哪个连接跳转过来的。页面跳转处 （可以做反爬处理）

**User-Agent**：用户身份 （用户代理 ）主要是用于浏览器告诉服务器自己的身份  用于判断是不是用户（可以做反爬处理）

x-requested-with : XMLHttpRequest：  ajax 请求

URL的组成部分大概分为三部分:

- 协议部分

- 域名部分
- 资源路径部分

格式说明:

```
scheme://host[:port]/path/…/[?query-string][#anchor]
```

- scheme：协议(例如：http, https, ftp)
- host：服务器的IP地址或者域名
- port：服务器的端口（如果是走协议默认端口，缺省端口80）
- path：访问资源的路径
- query-string：参数，发送给http服务器的数据
- anchor：锚（跳转到网页的指定锚点位置）   锚点：是不发起请求的

**4 记忆HTTP响应头的形式**

响应行：HTTP协议的版本        响应状态码      状态码的简单描述     

响应头：

- location：告诉客户端要跳转的正确url  

| 响应头         | 作用                                                         |
| -------------- | ------------------------------------------------------------ |
| Location       | 这个头配合302状态码使用，告诉用户端找谁。                    |
| Server         | 服务器通过这个头，告诉浏览器服务器的类型 （ JSP3/2.0.14 ） 一种Java服务器 |
| Content-Length | 服务器通过这个头，告诉浏览器回送数据的长度。                 |
| Content-Type   | 服务器通过这个头，回送数据的类型                             |
| Connection     | 服务器通过这个头，响应完是保持链接还是关闭链接。             |





页面跳转：

1 js中 window.location.

2 响应头中添加location.url

第二种好：因为第二种浏览器只返回一个响应头信息， 没有内容， 传输过程减少了流量， 不用读取js代码

**响应流程**

![1541864459045](D:\学习\py\个人学习笔记\爬虫\爬虫入门\响应加密流程.png)

中间人：路由器 交换机  运营商

中间人攻击：交换机在html文件body位置插入一段js代码，篡改数据。

解决方式：以密文的形式发送， 并用ca证书对随机密文加密， 防止密文被拦截。

**RSA算法**

- 非对称算法
- 公钥和私钥
- 公钥加密 私钥解密
- 私钥加密 公钥解密
- 私钥放在服务器  公钥+公司信息 = CA证书
- 浏览器向服务器请求公钥证书 -- -- 得到证书 --校验CA证书 --- CA证书在客户端生成随机密码 -- 公钥对随机密码进行加密 -- 将加密的内容传给服务器端 -- 服务器得到加密随机密码 -- 每次请求都会用随机密码对请求进行加密 -- 服务器会用随机密码对请求进行解密 -- 随机密码对响应加密， 发送给浏览器 -- 浏览器得到响应 -- 这个过程   只能得到加密信息，但是会得到证书          
- 第三方认证机构 -- 浏览器安装成功， 会内置第三方认证机构， 当拿到CA证书时， 浏览器会先进行校验 -- 如果中间人篡改证书， 验证就不会通过， 显示一个差

HTTPS：防止中间人篡改数据， 在传输过程中对请求和响应进行加密

- HTTP：不安全 性能高
- HTTPS：安全 性能低（因为多了加解密过程）

主流：HTTPS（ 微信小程序 IOS 安卓）

作为开发者：要做 ： （加解密web服务器已经帮我们全部实现好了）， HTTPS部署在nginx 或 Apache

- 1 生成公钥  私钥
- 2 提交公钥和公司信息到第三方认证机构签发CA证书
- 3 把CA证书和私钥部署到web服务器上

想要实现部署， 百度搜索：Nginx部署HTTPS   就可以了

第三放认证机构：阿里云和百度云

**5 了解 http响应状态码**

- 200 - 请求成功
- 301 - 资源（网页等）被永久转移到其它URL
- 404 - 请求的资源（网页等）不存在
- 500 - 内部服务器错误



### 1.4 字符串相关

##### 1 字符、字符集

字符(Character)是各种文字和符号的总称，包括各国家文字、标点符号、图形符号、数字等

字符集(Character set)是多个字符的集合

字符集包括：ASCII字符集、GB2312字符集、GB18030字符集、Unicode字符集等

<u>ASCII编码是1个字节，而Unicode编码 **通常** 是2个字节</u>     **还可能是3个字节**  。65553 种可能， 但是 Unicode 还有17个字符平面映射， 所以是65535*17 中可能。其中一个主平面，16个为辅助平面， 目前第四辅助平面还没用到。

**UTF-8是Unicode的实现方式**之一，UTF-8是它是一种变长的编码方式，可以是1，2，3，4 个字节

```
Unicode（统一码、万国码、单一码）是计算机科学领域里的一项业界标准，包括字符集、编码方案等。Unicode 是为了解决传统的字符编码方案的局限而产生的，它为每种语言中的每个字符设定了统一并且唯一的二进制编码，以满足跨语言、跨平台进行文本转换、处理的要求。1990年开始研发，1994年正式公布。 
```

**2 python3中两种字符串类型：**

- str : unicode的呈现形式
- bytes :字节类型，互联网上数据的都是以二进制的方式(字节类型)传输的

关于bytes的拓展阅读：<https://segmentfault.com/a/1190000004450876> 

### 3 str和bytes类型的互相转换：

- str 使用encode方法转化为 bytes

```
s = 'abc'
print(type(s))
#str编码变为bytes类型
b = s.encode
print(type(b))
```

- bytes 通过decode转化为 str

```
b = b'abc'
print(type(b))
#bytes类型解码成为str类型
s = b.decode()
print(type(s))
```



**urllib库**

自定义请求头

1 指定User-Agent ：指定一个用户 

自定义请求参数

2  pycharm中 请求参数中如果写入空格、中文， 会报错。（）

- 原因：请求行用空格区分的， 加空格会染该协议紊乱， 解决：url编码转义

3 字符编码问题（下面两个什么时候用）

- 1 decode 和encode区别
- 2 Unicode和utf-8

字符编码（decode 和encode区别）

- 字节串（二进制）：
  - [:1]取一个字节  
  - bytes（Python2 中str）
- 字符串：
  - [:1] 取一个字符
  - str（Python2 中Unicode）
- 转换：
  - 字节串->字符串 decode   Unicode    例如 a是b   这里len() = 4
  - 字符串->字节串 encode   utf-8          例如 a是b   这里len() = 6

如何使用decode 和 encode：

- 1 确认环境
- 2 确认转换对象是字节串还是字符串

为什么用utf-8（Unicode和utf-8）

Unicode收录所有编码， 但是两个字节成为一个字符， 问题是增加了内存。

规定：不允许Unicode进行**网络传输或数据存储**， 必须进行转换之后才能进行存储。

utf-8：使用Unicode 的一种形式，帮助Unicode 进行一种转换-> 数据量会变小。

- 转换后字节数从1到4不等
- 本质上帮助Unicode 完成网络传输或者数据存储

又发现的问题， 对中文来说utf-8转换Unicode后反而变大了（用utf-8转换Unicode的格式，英文变为一个字节串， 中文变为3个）

例题：有一个文件UTF-8 的文本格式的文件， 大小都为10G， 计算UTF-8 编码格式文件中的字符个数， 计算机内存为128M。

![1541865968569](D:\学习\py\个人学习笔记\爬虫\爬虫入门\utf-8.png)

从指针角度考虑：根据二进制数据前面1的个数判断指针跳过的个数， （避开误切一个完整的字符）

基于网络的问题：

- 1 会不会HTTP（传输层）
- 2 TCP知道吗？  HTTP 关系？  
- 3  ip协议（网络层）？数据包传输
  - 原地址 
  - 目标地址
- 4 TCP在ip上解决了什么问题
  - 1 数据包长度限制（一个5G的数据包生成若干个ip数据包）
  - 2 对数据包进行编号， 保证传输是有序的（ 怎么知道若干个包是属于一个文件呢？？）
- 5 三次握手本质：解决的是顺序问题？？
  - 第一次握手成功：则以后发送的数据包从1开始
  - 第二次握手成功：
  - 第三次握手成功：
- 6 UDP:     1 丢包       2 没有编号（所以原理上没法进行大文件的）解决方式
  - 1 解决文件没有编号的问题：应用层进行编号（上一层）， 就可以实现UDP的有序传输了
- 7 qq 微信 视频   用户 -- 直播服务器 -- 用户：（所以直播公司花大量的前在带宽上）
  - 1 解决：手机直连就可以。但是怎么实现？(路由缓存：打洞)
    - 手机一号 二号：首先手机一号与手机二号开视频，发送请求到腾讯服务器， 腾讯服务器接收到请求会先让二号手机发送视频请求到一号， 但是会被一号附近的路由器拦截， 但是这会二号路由器中已经有了缓存：打好洞了， 这会腾讯服务器会实时告诉一号手机， 已经打好洞了， 就可以通过一号附近的路由器， 连接二号路由器， 因为二号路由器中缓存， 就可以连接指定的手机或电脑。









